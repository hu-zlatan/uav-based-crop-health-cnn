import os
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
from sklearn.model_selection import train_test_split
from tqdm import tqdm

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆç›¸å¯¹è·¯å¾„ + æ— colorå­æ–‡ä»¶å¤¹ï¼‰ =====================
# è„šæœ¬è·¯å¾„ï¼šsrc/data/prepare_tomato_data.py â†’ é¡¹ç›®æ ¹ç›®å½•/data/raw
RAW_DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data", "raw")
PROCESSED_DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), "data", "processed")
IMAGE_SIZE = (256, 256)
TEST_SIZE = 0.2
VAL_SIZE = 0.1
RANDOM_SEED = 42

# ===================== æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆè§£æTomato___XXXå‘½åï¼‰ =====================
def parse_tomato_label(folder_name):
    """
    è§£æTomato___XXXæ ¼å¼çš„æ–‡ä»¶å¤¹åï¼Œæå–èƒè¿«ç±»å‹æ ‡ç­¾
    ç¤ºä¾‹ï¼šTomato___Bacterial_spot â†’ Bacterial_spot
    ç¤ºä¾‹ï¼šTomato___Healthy â†’ Healthy
    """
    pattern = r"Tomato___(.*)"
    match = re.match(pattern, folder_name)
    if match:
        label = match.group(1).replace("_", " ").title()
        return label.strip()
    else:
        return None

def create_dirs():
    """åˆ›å»ºå¿…è¦ç›®å½• + éªŒè¯åŸå§‹æ•°æ®è·¯å¾„"""
    os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)
    print(f"âœ… é¢„å¤„ç†è¾“å‡ºç›®å½•å°±ç»ªï¼š{PROCESSED_DATA_DIR}")
    
    # éªŒè¯rawè·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(RAW_DATA_DIR):
        raise FileNotFoundError(f"âŒ åŸå§‹æ•°æ®è·¯å¾„ä¸å­˜åœ¨ï¼š{RAW_DATA_DIR}ï¼Œè¯·ç¡®è®¤æ–‡ä»¶å·²å¤åˆ¶åˆ°data/raw")
    print(f"âœ… åŸå§‹æ•°æ®è·¯å¾„éªŒè¯é€šè¿‡ï¼š{RAW_DATA_DIR}")

def analyze_tomato_dataset():
    """
    æ ¸å¿ƒï¼šç›´æ¥éå†data/rawä¸‹çš„Tomato___XXXæ–‡ä»¶å¤¹ï¼Œç»Ÿè®¡æ¯ç±»æ ‡ç­¾+æ ·æœ¬æ•°
    ï¼ˆæ— colorå­æ–‡ä»¶å¤¹ï¼Œç›´æ¥å¤„ç†rawæ ¹ç›®å½•ä¸‹çš„ç•ªèŒ„æ–‡ä»¶å¤¹ï¼‰
    """
    sample_list = []
    class_count = {}  # {æ ‡ç­¾: æ ·æœ¬æ•°}

    # ç›´æ¥éå†RAW_DATA_DIRï¼ˆdata/rawï¼‰ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å¤¹
    all_folders = os.listdir(RAW_DATA_DIR)
    for folder_name in tqdm(all_folders, desc="éå†ç•ªèŒ„èƒè¿«ç±»åˆ«æ–‡ä»¶å¤¹"):
        folder_path = os.path.join(RAW_DATA_DIR, folder_name)
        
        # ä»…å¤„ç†ï¼šæ–‡ä»¶å¤¹ + ä»¥Tomato___å¼€å¤´
        if not os.path.isdir(folder_path) or not folder_name.startswith("Tomato___"):
            print(f"âš ï¸  è·³è¿‡éç•ªèŒ„ç±»åˆ«æ–‡ä»¶å¤¹ï¼š{folder_name}")
            continue
        
        # è§£æèƒè¿«æ ‡ç­¾
        stress_label = parse_tomato_label(folder_name)
        if not stress_label:
            print(f"âš ï¸  è·³è¿‡æ— æ•ˆå‘½åæ–‡ä»¶å¤¹ï¼š{folder_name}")
            continue
        
        # ç»Ÿè®¡è¯¥æ–‡ä»¶å¤¹ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
        img_files = [
            f for f in os.listdir(folder_path) 
            if f.lower().endswith((".jpg", ".png", ".jpeg", ".bmp"))
        ]
        if not img_files:
            print(f"âš ï¸  ç±»åˆ«{stress_label}ä¸‹æ— å›¾ç‰‡ï¼Œè·³è¿‡")
            continue
        
        # è®°å½•ç±»åˆ«æ ·æœ¬æ•°
        class_count[stress_label] = len(img_files)
        
        # è®°å½•æ¯ä¸ªæ ·æœ¬çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç›¸å¯¹è·¯å¾„+ç»å¯¹è·¯å¾„ï¼‰
        for img_file in img_files:
            # ç›¸å¯¹è·¯å¾„ï¼šdata/raw/XXX/XXX.jpg
            relative_img_path = os.path.join("data", "raw", folder_name, img_file)
            # ç»å¯¹è·¯å¾„ï¼šç”¨äºåŠ è½½å›¾ç‰‡
            absolute_img_path = os.path.join(folder_path, img_file)
            
            sample_list.append({
                "img_path": relative_img_path,
                "absolute_img_path": absolute_img_path,
                "folder_name": folder_name,
                "stress_label": stress_label,
                "is_healthy": True if stress_label == "Healthy" else False,
                "image_size": IMAGE_SIZE
            })

    # ç©ºæ•°æ®é›†æ ¡éªŒ
    if not sample_list:
        raise ValueError("âŒ æœªæ‰¾åˆ°ä»»ä½•ç•ªèŒ„æ ·æœ¬ï¼è¯·ç¡®è®¤data/rawä¸‹æœ‰Tomato___XXXæ ¼å¼çš„æ–‡ä»¶å¤¹")
    
    # è½¬æ¢ä¸ºDataFrame
    df = pd.DataFrame(sample_list)
    
    # ========== è¾“å‡ºç±»åˆ«-æ ·æœ¬æ•°ç»Ÿè®¡ ==========
    print("\n" + "="*50)
    print("ğŸ… ç•ªèŒ„èƒè¿«ç±»åˆ« - æ ·æœ¬æ•°ç»Ÿè®¡ï¼ˆæŒ‰æ ·æœ¬æ•°é™åºï¼‰")
    print("="*50)
    sorted_class_count = dict(sorted(class_count.items(), key=lambda x: x[1], reverse=True))
    for idx, (label, count) in enumerate(sorted_class_count.items(), 1):
        print(f"{idx:2d}. {label:<20} : {count:>5} å¼ ")
    
    # æ±‡æ€»ä¿¡æ¯
    total_samples = sum(class_count.values())
    total_classes = len(class_count)
    print("="*50)
    print(f"ğŸ“Š æ±‡æ€»ï¼šå…± {total_classes} ä¸ªèƒè¿«ç±»åˆ«ï¼Œæ€»è®¡ {total_samples} å¼ å›¾ç‰‡")
    print(f"ğŸ¥¬ å¥åº·æ ·æœ¬æ•°ï¼š{class_count.get('Healthy', 0)} å¼ ")
    print("="*50)

    # ========== ä¿å­˜ç»Ÿè®¡ç»“æœåˆ°CSV ==========
    class_count_df = pd.DataFrame({
        "stress_label": list(class_count.keys()),
        "sample_count": list(class_count.values()),
        "sample_ratio": [f"{count/total_samples*100:.2f}%" for count in class_count.values()]
    }).sort_values(by="sample_count", ascending=False)
    class_count_csv_path = os.path.join(PROCESSED_DATA_DIR, "class_sample_count.csv")
    class_count_df.to_csv(class_count_csv_path, index=False, encoding="utf-8")
    print(f"\nâœ… ç±»åˆ«-æ ·æœ¬æ•°ç»Ÿè®¡å·²ä¿å­˜ï¼š{class_count_csv_path}")

    # ========== å¯è§†åŒ–ç±»åˆ«åˆ†å¸ƒ ==========
    plt.figure(figsize=(18, 8))
    sns.barplot(x=list(sorted_class_count.keys()), y=list(sorted_class_count.values()), palette="viridis")
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for idx, count in enumerate(sorted_class_count.values()):
        plt.text(idx, count + 5, str(count), ha="center", fontsize=9)
    plt.title("Tomato Stress Class - Sample Count Distribution (256Ã—256)", fontsize=14)
    plt.xlabel("Stress Label", fontsize=12)
    plt.ylabel("Number of Samples", fontsize=12)
    plt.xticks(rotation=45, ha="right")
    plt.tight_layout()
    # ä¿å­˜å›¾è¡¨
    class_dist_png_path = os.path.join(PROCESSED_DATA_DIR, "class_sample_distribution.png")
    plt.savefig(class_dist_png_path, dpi=150)
    plt.close()
    print(f"âœ… ç±»åˆ«åˆ†å¸ƒå¯è§†åŒ–å·²ä¿å­˜ï¼š{class_dist_png_path}")

    return df, class_count

def split_dataset(df, class_count):
    """åˆ†å±‚åˆ’åˆ†è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†ï¼ˆä¿è¯æ¯ç±»æ ·æœ¬åˆ†å¸ƒå‡åŒ€ï¼‰"""
    # æ ‡ç­¾â†’æ•°å­—ç¼–ç æ˜ å°„
    stress_labels = sorted(class_count.keys())
    label_to_idx = {label: idx for idx, label in enumerate(stress_labels)}
    df["label"] = df["stress_label"].map(label_to_idx)

    # åˆ†å±‚åˆ’åˆ†
    train_val_df, test_df = train_test_split(
        df, test_size=TEST_SIZE, stratify=df["stress_label"], random_state=RANDOM_SEED
    )
    train_df, val_df = train_test_split(
        train_val_df, test_size=VAL_SIZE/(1-TEST_SIZE), stratify=train_val_df["stress_label"], random_state=RANDOM_SEED
    )

    # ä¿å­˜åˆ’åˆ†ç»“æœï¼ˆä»…ä¿ç•™æ ¸å¿ƒåˆ—ï¼‰
    save_cols = ["img_path", "stress_label", "label", "is_healthy"]
    train_df[save_cols].to_csv(os.path.join(PROCESSED_DATA_DIR, "train.csv"), index=False, encoding="utf-8")
    val_df[save_cols].to_csv(os.path.join(PROCESSED_DATA_DIR, "val.csv"), index=False, encoding="utf-8")
    test_df[save_cols].to_csv(os.path.join(PROCESSED_DATA_DIR, "test.csv"), index=False, encoding="utf-8")

    # ä¿å­˜æ ‡ç­¾æ˜ å°„
    np.save(os.path.join(PROCESSED_DATA_DIR, "label_to_idx.npy"), label_to_idx)
    np.save(os.path.join(PROCESSED_DATA_DIR, "idx_to_label.npy"), {v: k for k, v in label_to_idx.items()})

    # æ‰“å°åˆ’åˆ†ç»“æœ
    print("\n=== æ•°æ®é›†åˆ’åˆ†ç»“æœ ===")
    print(f"è®­ç»ƒé›†ï¼š{len(train_df)} å¼  ({len(train_df)/len(df)*100:.1f}%)")
    print(f"éªŒè¯é›†ï¼š{len(val_df)} å¼  ({len(val_df)/len(df)*100:.1f}%)")
    print(f"æµ‹è¯•é›†ï¼š{len(test_df)} å¼  ({len(test_df)/len(df)*100:.1f}%)")

    # éªŒè¯è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ
    print("\n=== è®­ç»ƒé›†å„ç±»åˆ«æ ·æœ¬æ•°ï¼ˆå‰5ç±»ï¼‰===")
    train_class_count = train_df["stress_label"].value_counts().head()
    for label, count in train_class_count.items():
        print(f"{label:<20} : {count:>5} å¼ ")

    return train_df, val_df, test_df, label_to_idx

def validate_image_preprocessing(df):
    """éªŒè¯å›¾ç‰‡é¢„å¤„ç†ï¼ˆ256Ã—256ï¼‰"""
    sample_df = df.sample(10, random_state=RANDOM_SEED)
    plt.figure(figsize=(18, 10))

    for idx, (_, row) in enumerate(sample_df.iterrows()):
        try:
            # ç”¨ç»å¯¹è·¯å¾„åŠ è½½å›¾ç‰‡
            img = Image.open(row["absolute_img_path"]).convert("RGB")
            img_resized = img.resize(IMAGE_SIZE)
            img_array = np.array(img_resized) / 255.0

            # æ ¡éªŒå°ºå¯¸
            assert img_array.shape == (256, 256, 3), f"å°ºå¯¸é”™è¯¯ï¼š{img_array.shape}"

            # æå–æ–‡ä»¶åï¼ˆæ— åæ–œæ ï¼‰
            img_filename = os.path.basename(row["absolute_img_path"])
            short_filename = img_filename[:10]
            
            # å¯è§†åŒ–
            plt.subplot(2, 5, idx+1)
            plt.imshow(img_array)
            plt.title(f"{row['stress_label']}\n({short_filename}...)", fontsize=9)
            plt.axis("off")
        except Exception as e:
            print(f"âš ï¸  å›¾ç‰‡{row['absolute_img_path']}å¤„ç†å¤±è´¥ï¼š{e}")
            continue

    plt.suptitle("Sample Preprocessed Tomato Images (256Ã—256)", fontsize=14)
    plt.tight_layout()
    sample_png_path = os.path.join(PROCESSED_DATA_DIR, "sample_images.png")
    plt.savefig(sample_png_path, dpi=150)
    plt.close()
    print(f"âœ… æ ·æœ¬é¢„å¤„ç†éªŒè¯å®Œæˆï¼š{sample_png_path}")

# ===================== ä¸»å‡½æ•° =====================
if __name__ == "__main__":
    create_dirs()
    # æ ¸å¿ƒï¼šç»Ÿè®¡ç±»åˆ«+æ ·æœ¬æ•°
    df, class_count = analyze_tomato_dataset()
    # åˆ’åˆ†æ•°æ®é›†
    train_df, val_df, test_df, label_to_idx = split_dataset(df, class_count)
    # éªŒè¯é¢„å¤„ç†
    validate_image_preprocessing(train_df)

    print("\nğŸ¯ æ•°æ®é¢„å¤„ç†å®Œæˆï¼æ ¸å¿ƒè¾“å‡ºæ–‡ä»¶ï¼š")
    print(f"  1. {PROCESSED_DATA_DIR}/class_sample_count.csv â†’ ç±»åˆ«-æ ·æœ¬æ•°ç»Ÿè®¡")
    print(f"  2. {PROCESSED_DATA_DIR}/class_sample_distribution.png â†’ ç±»åˆ«åˆ†å¸ƒå¯è§†åŒ–")
    print(f"  3. {PROCESSED_DATA_DIR}/label_to_idx.npy â†’ æ ‡ç­¾-æ•°å­—ç¼–ç æ˜ å°„")
    print(f"  4. {PROCESSED_DATA_DIR}/train/val/test.csv â†’ åˆ’åˆ†åçš„æ•°æ®é›†")